{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOpTxfhOPBCTf3vd3xjES3e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamza1122/ML-Optuna/blob/master/Untitled100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh1NuNUi85SZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a68a0552-2007-4311-9956-42f8b687124a"
      },
      "source": [
        "!pip install optuna\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/32/266d4afd269e3ecd7fcc595937c1733f65eae6c09c3caea74c0de0b88d78/optuna-1.5.0.tar.gz (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 2.9MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/1e/cabc75a189de0fbb2841d0975243e59bde8b7822bacbb95008ac6fe9ad47/alembic-1.4.2.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 9.1MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/59/4db149d8962dc29a37c8bc08cd79185935527af9a27259a2d80cac707212/cliff-3.3.0-py3-none-any.whl (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.9MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0e/7f/ebba8a7950487c760c245168f7ba318b35bf0cac9c0eba30b9fb50150a20/cmaes-0.5.1-py3-none-any.whl\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/00/0d/22c73c2eccb21dd3498df7d22c0b1d4a30f5a5fb3feb64e1ce06bc247747/colorlog-4.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.18)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
            "Collecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Collecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/17/641b563f5839c61a4767a070644ff2be3f70fe0d8ddd879a52dbd4976980/cmd2-1.2.1-py3-none-any.whl (121kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 15.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (1.12.0)\n",
            "Collecting stevedore>=1.20.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/f4/041afc90e684f2b7d00a7f49abcbaf0b8c03e916bbc398ce49dce2a3c408/stevedore-3.2.0-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.2MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/ba/aa953a11ec014b23df057ecdbc922fdb40ca8463466b1193f3367d2711a6/pbr-5.4.5-py2.py3-none-any.whl (110kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 16.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable<0.8,>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (0.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (19.3.0)\n",
            "Requirement already satisfied: setuptools>=34.4 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (49.1.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/5b/55866e1cde0f86f5eec59dab5de8a66628cb0d53da74b8dbc15ad8dabda3/pyperclip-1.8.0.tar.gz\n",
            "Requirement already satisfied: importlib-metadata>=1.6.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.6.0; python_version < \"3.8\"->cmd2!=0.8.3,>=0.8.0->cliff->optuna) (3.1.0)\n",
            "Building wheels for collected packages: alembic\n",
            "  Building wheel for alembic (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.2-cp36-none-any.whl size=159543 sha256=6bb759cff883c3b376f909ab1679813a7fd197bc19fb6863445e5ac2ff2ad0ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/04/83/76023f7a4c14688c0b5c2682a96392cfdd3ee4449eaaa287ef\n",
            "Successfully built alembic\n",
            "Building wheels for collected packages: optuna, pyperclip\n",
            "  Building wheel for optuna (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-1.5.0-cp36-none-any.whl size=276145 sha256=3f26826ac41569465aded6f66b21db0c606e7a2481b0d30c255d925b34e11dee\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/21/78/4f5529e0c757ababc4217eb9adf1886d21eb22bb1ab98c33c5\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.0-cp36-none-any.whl size=8693 sha256=a55a6838aabaf60dc060189afc8e666b7a615e4ccb22ad67152137eef51e4d9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/ac/0a/b784f0afe26eaf52e88a7e15c7369090deea0354fa1c6fc689\n",
            "Successfully built optuna pyperclip\n",
            "Installing collected packages: python-editor, Mako, alembic, colorama, pyperclip, cmd2, pbr, stevedore, cliff, cmaes, colorlog, optuna\n",
            "Successfully installed Mako-1.1.3 alembic-1.4.2 cliff-3.3.0 cmaes-0.5.1 cmd2-1.2.1 colorama-0.4.3 colorlog-4.1.0 optuna-1.5.0 pbr-5.4.5 pyperclip-1.8.0 python-editor-1.0.4 stevedore-3.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsJ9cidZJpYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model configuration\n",
        "img_width, img_height = 32, 32\n",
        "batch_size = 250\n",
        "no_epochs = 3\n",
        "no_classes = 10\n",
        "validation_split = 0.2\n",
        "verbosity =1\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSg5TUveJwTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "2553a4ca-b119-4fdb-9021-bc67210cc57c"
      },
      "source": [
        "# Load CIFAR10 dataset\n",
        "\n",
        "\n",
        "# Data loader splitting dataset \n",
        "(input_train, target_train), (input_test, target_test) = cifar10.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# Visualize CIFAR10 dataset\n",
        "import matplotlib.pyplot as plt\n",
        "classes = {\n",
        "  0: 'airplane',\n",
        "  1: 'automobile',\n",
        "  2: 'bird',\n",
        "  3: 'cat',\n",
        "  4: 'deer',\n",
        "  5: 'dog',\n",
        "  6: 'frog',\n",
        "  7: 'horse',\n",
        "  8: 'ship',\n",
        "  9: 'truck'\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI1xii9qNCKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "try:\n",
        "    os.mkdir('dataloader')\n",
        "    os.mkdir('dataloader/train')\n",
        "    os.mkdir('dataloader/test')\n",
        "    os.mkdir('dataloader/val')\n",
        "except FileExistsError:\n",
        "    print(\"Directory already exists\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu97NIfkKA7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    input_train = input_train.reshape(input_train.shape[0],3, img_width, img_height)\n",
        "    input_test = input_test.reshape(input_test.shape[0], 3, img_width, img_height)\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_train = input_train.reshape(input_train.shape[0], img_width, img_height, 3)\n",
        "    input_test = input_test.reshape(input_test.shape[0], img_width, img_height, 3)\n",
        "    input_shape = (img_width  , img_height, 3)\n",
        "\n",
        "# Parse numbers as floats\n",
        "input_train = input_train.astype('float32')\n",
        "input_test = input_test.astype('float32')\n",
        "\n",
        "# Convert them into black or white: [0, 1].\n",
        "input_train = input_train / 255\n",
        "input_test = input_test / 255\n",
        "\n",
        "# Convert target vectors to categorical targets\n",
        "target_train = keras.utils.to_categorical(target_train, no_classes)\n",
        "target_test = keras.utils.to_categorical(target_test, no_classes)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40XGwlnJBrfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import optuna\n",
        "\n",
        "#Keys_list is the list of input which does the sanity check before running the model\n",
        "def check_dict_contains_keys(keylist,values):\n",
        "  print(keylist,values)\n",
        "\n",
        "class ExperimentManager:\n",
        "\n",
        "    # parameterized constructor\n",
        "    def __init__(self,model,hps_dict,datapath,callbacks,optuna_args_dict):\n",
        "        self.model = model\n",
        "        self.datapath=datapath\n",
        "        self.hps_dict=hps_dict\n",
        "        self.callbacks=callbacks\n",
        "        self.optuna_data=optuna_args_dict\n",
        "\n",
        "\n",
        "        check_dict_contains_keys(self.optuna_data.keys(),self.optuna_data.values())\n",
        "    \n",
        "    def sanity(self):\n",
        "      keyword_list = ['train','test','val']\n",
        "      if all(word in datapath for word in keyword_list):\n",
        "         display='All Sub-folder exists'\n",
        "      else:\n",
        "        display='User Should have three sub-folders'   \n",
        "      \n",
        "      return display\n",
        "     \n",
        "\n",
        "    def objective(self,trial):\n",
        "\n",
        "      x = trial.suggest_uniform('x', -10, 10)\n",
        "      #Step 2 part (b)\n",
        "      hp_filters = trial.suggest_categorical(\"hp_filters\",hparams['hp_filters'])\n",
        "      hp_kernel_size= trial.suggest_categorical(\"hp_kernel_size\",hparams['hp_kernel_size'])\n",
        "      hp_strides= trial.suggest_categorical(\"hp_strides\",hparams['hp_strides'])\n",
        "      hp_activation= trial.suggest_categorical(\"hp_activation\",hparams['hp_activation'])\n",
        "      \n",
        "     \n",
        "      #Step 3\n",
        "      model = Sequential()\n",
        "      model.add(Conv2D(32, kernel_size=hp_kernel_size,strides=hp_strides,filters=hp_filters,activation=hp_activation, input_shape=input_shape))\n",
        "      model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "      model.add(Dropout(0.25))\n",
        "      model.add(Conv2D(64, kernel_size=hp_kernel_size,strides=hp_strides,activation=hp_activation))\n",
        "      model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "      model.add(Dropout(0.25))\n",
        "      model.add(Flatten())\n",
        "      model.add(Dense(256, activation='relu'))\n",
        "      model.add(Dense(no_classes, activation='softmax'))\n",
        "      model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])\n",
        "      \n",
        "      #step 4\n",
        "      model.fit(input_train, target_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=no_epochs,\n",
        "          verbose=verbosity,\n",
        "          validation_split=validation_split,\n",
        "          callbacks=keras_callbacks)\n",
        "\n",
        "      \n",
        "      #step 5\n",
        "      score = model.evaluate(input_test, target_test, verbose=0)  \n",
        "      print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "      return score[1]\n",
        "\n",
        "    def rando(self):\n",
        "      #Step 1   sample new values of the hps\n",
        "      \n",
        "      # we can use \n",
        "      hparams1={ \n",
        "           \"hps_1\":{'dtype':'int', 'min':1, 'max':6, 'sampler':'uniform'},\n",
        "           \"hps_2\":{'dtype':'int', 'min':1, 'max':6},\n",
        "           \"hps_3\":{'dtype':'int', 'min':1, 'max':6},\n",
        "           \"hps_4\":{'dtype':'int', 'min':1, 'max':6},\n",
        "            }\n",
        "      \n",
        "      \n",
        "      \n",
        "      #Step 2 part a\n",
        "      for name,value in hparams.items():\n",
        "        print(name, '->', value)\n",
        "      \n",
        "      print(self.sanity())\n",
        "      \n",
        "      \n",
        "      if self.model=='CNN':\n",
        "         study = optuna.create_study(study_name=optuna_args_dict['name'],storage=optuna_args_dict['db'],direction=optuna_args_dict['direction'])\n",
        "         study.optimize(self.objective, n_trials=30)\n",
        "         print(study.best_params)  \n",
        "          \n",
        "       \n",
        "# creating object of the class\n",
        "# this will invoke parameterized constructor\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGEH_QMz9HU7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3fa26cac-1c93-4cbe-98ef-87734bcc77ff"
      },
      "source": [
        "hparams={\n",
        "\"hp_filters\" : [64, 128, 256],\n",
        "\"hp_kernel_size\" : [3, 5],\n",
        "\"hp_strides\" : [1, 2],\n",
        "\"hp_activation\" : [\"relu\", \"linear\", \"elu\", \"selu\"],\n",
        "\"hp_lrmin\" : 1e-5,\n",
        "\"hp_lrmax\" : 1e-1\n",
        "}\n",
        "# Define Tensorboard as a Keras callback\n",
        "tensorboard = TensorBoard(\n",
        "  log_dir='.\\logs',\n",
        "  histogram_freq=1,\n",
        "  write_images=True\n",
        ")\n",
        "keras_callbacks = [\n",
        "  tensorboard\n",
        "]\n",
        "\n",
        "optuna_args_dict={\n",
        "\"db\":'sqlite:///',\n",
        "\"name\":'macula',\n",
        "\"direction\": 'maximize',\n",
        "\"metric\": 'accuracy'\n",
        "}\n",
        "\n",
        "model='CNN'\n",
        "datapath=os.listdir('dataloader')\n",
        "\n",
        "\n",
        "obj = ExperimentManager(model, hparams, datapath, keras_callbacks, optuna_args_dict)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['db', 'name', 'direction', 'metric']) dict_values(['sqlite:///', 'macula', 'maximize', 'accuracy'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA5dAmuJ9LZ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "d7e07650-7273-4a86-e65a-d50268d7654c"
      },
      "source": [
        "obj.rando()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hp_filters -> [64, 128, 256]\n",
            "hp_kernel_size -> [3, 5]\n",
            "hp_strides -> [1, 2]\n",
            "hp_activation -> ['relu', 'linear', 'elu', 'selu']\n",
            "hp_lrmin -> 1e-05\n",
            "hp_lrmax -> 0.1\n",
            "All Sub-folder exists\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-07-21 09:27:30,814] A new study created with name: macula\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "40000/40000 [==============================] - 13s 325us/step - loss: 1.8677 - accuracy: 0.3117 - val_loss: 1.5974 - val_accuracy: 0.4199\n",
            "Epoch 2/3\n",
            "40000/40000 [==============================] - 13s 316us/step - loss: 1.5527 - accuracy: 0.4342 - val_loss: 1.4480 - val_accuracy: 0.4726\n",
            "Epoch 3/3\n",
            "40000/40000 [==============================] - 13s 315us/step - loss: 1.4495 - accuracy: 0.4762 - val_loss: 1.3625 - val_accuracy: 0.5097\n",
            "Test loss: 1.352662566757202 / Test accuracy: 0.5001000165939331\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[I 2020-07-21 09:28:11,129] Finished trial#0 with value: 0.5001000165939331 with parameters: {'x': 1.1334286433654235, 'hp_filters': 128, 'hp_kernel_size': 5, 'hp_strides': 2, 'hp_activation': 'elu'}. Best is trial#0 with value: 0.5001000165939331.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/3\n",
            "13000/40000 [========>.....................] - ETA: 35s - loss: 1.9067 - accuracy: 0.3058"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCfiC-jcCOnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " hparams={ \n",
        "           \"hps_1\":{'dtype':'int', 'min':1, 'max':6, 'sampler':'uniform'},\n",
        "           \"hps_2\":{'dtype':'int', 'min':1, 'max':6},\n",
        "           \"hps_3\":{'dtype':'int', 'min':1, 'max':6},\n",
        "           \"hps_4\":{'dtype':'int', 'min':1, 'max':6},\n",
        "            }"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZlBOujBLR_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9237a07f-3bd0-4c07-8d8a-b671ad60e27e"
      },
      "source": [
        "hparams[\"hps_1\"]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dtype': 'int', 'max': 6, 'min': 1, 'sampler': 'uniform'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35PQPL9PLUxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K022VZkHTH0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aXscr0MXAK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}